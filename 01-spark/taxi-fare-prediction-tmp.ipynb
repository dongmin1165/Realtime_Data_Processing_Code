{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecba548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9d8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-duration-prediction\")\\\n",
    "            .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "            .config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2745af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_files = \"/Users/keon/fastcampus/data-engineering/01-spark/data/trips/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701bee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = spark.read.csv(f\"file:///{trip_files}\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb77c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba52ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c365bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    trip_distance,\n",
    "    total_amount\n",
    "FROM\n",
    "    (SELECT\n",
    "        *,\n",
    "        TO_DATE(t.tpep_pickup_datetime) AS pickup_date\n",
    "    FROM\n",
    "        trips t)\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND pickup_date >= '2021-01-01'\n",
    "    AND pickup_date < '2021-08-01'\n",
    "\"\"\"\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd561ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play with data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    *,\n",
    "    trip_distance / duration / 60 / 60 AS mph\n",
    "FROM\n",
    "    data\n",
    "\"\"\"\n",
    "res = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f4682b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+--------------------+\n",
      "|summary|     trip_distance|         duration|                 mph|\n",
      "+-------+------------------+-----------------+--------------------+\n",
      "|  count|          13125582|         13125582|            13125582|\n",
      "|   mean| 2.882109632929013|903.7218041836164|1.049888189940366...|\n",
      "| stddev|3.8203201017216077|3557.275401003693|7.961356651144816E-6|\n",
      "|    min|              0.01|                1|3.250079301934967...|\n",
      "|    max|             475.5|          1729062|0.005388888888888888|\n",
      "+-------+------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e44e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500134\n",
      "2625906\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=1)\n",
    "print(train_df.count())\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33632d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96c55249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+\n",
      "|trip_distance|total_amount|features|\n",
      "+-------------+------------+--------+\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "+-------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vassembler = VectorAssembler(inputCols=['trip_distance'], outputCol='features')\n",
    "vtrain_df = vassembler.transform(train_df)\n",
    "vtrain_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c53bbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7ec99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=50,\n",
    "    labelCol=\"total_amount\",\n",
    "    featuresCol=\"features\",\n",
    "    elasticNetParam=0.5, \n",
    "    regParam=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c4bac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c457bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46aa3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = vassembler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "327e1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "627c4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+-----------------+\n",
      "|trip_distance|total_amount|features|       prediction|\n",
      "+-------------+------------+--------+-----------------+\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.3|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "|         0.01|         3.8|  [0.01]|9.420298598289232|\n",
      "+-------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59e55bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "distance_list = [1.1, 5.5, 10.5, 30.0]\n",
    "distances_df = spark.createDataFrame(distance_list, DoubleType()).toDF(\"trip_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cc43781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|          1.1|\n",
      "|          5.5|\n",
      "|         10.5|\n",
      "|         30.0|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fd9f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdistances_df = vassembler.transform(distances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "170e874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|trip_distance|features|\n",
      "+-------------+--------+\n",
      "|          1.1|   [1.1]|\n",
      "|          5.5|   [5.5]|\n",
      "|         10.5|  [10.5]|\n",
      "|         30.0|  [30.0]|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdistances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75e1ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------------+\n",
      "|trip_distance|features|        prediction|\n",
      "+-------------+--------+------------------+\n",
      "|          1.1|   [1.1]|12.666196220094683|\n",
      "|          5.5|   [5.5]| 25.76890221637357|\n",
      "|         10.5|  [10.5]|40.658340848508665|\n",
      "|         30.0|  [30.0]| 98.72715151383554|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(vdistances_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9cea1",
   "metadata": {},
   "source": [
    "# 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "675176d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7fe205918d30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "852c8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  6.264524760859883\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", model.summary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac8b9fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.767718727019524\n"
     ]
    }
   ],
   "source": [
    "print(\"R2: \", model.summary.r2)\n",
    "# R2:  0.018565176935511962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5eb8cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|     trip_distance|      total_amount|\n",
      "+-------+------------------+------------------+\n",
      "|  count|          10500134|          10500134|\n",
      "|   mean|2.8817834020028044|17.972147144070217|\n",
      "| stddev| 3.821344671677971|12.998135264013039|\n",
      "|    min|              0.01|              0.01|\n",
      "|    max|             475.5|            4973.3|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bc1b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
