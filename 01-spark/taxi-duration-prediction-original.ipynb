{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecba548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9d8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-duration-prediction\")\\\n",
    "            .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "            .config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2745af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_files = \"/Users/keon/fastcampus/data-engineering/01-spark/data/trips/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701bee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = spark.read.csv(f\"file:///{trip_files}\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb77c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba52ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c365bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    trip_distance,\n",
    "    duration\n",
    "FROM\n",
    "    (SELECT\n",
    "        *,\n",
    "        TO_DATE(t.tpep_pickup_datetime) AS pickup_date,\n",
    "        UNIX_TIMESTAMP(t.tpep_dropoff_datetime) - UNIX_TIMESTAMP(t.tpep_pickup_datetime) AS duration\n",
    "    FROM\n",
    "        trips t)\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND pickup_date >= '2021-01-01'\n",
    "    AND pickup_date < '2021-08-01'\n",
    "    AND duration > 0\n",
    "\"\"\"\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e44e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10499761\n",
      "2625821\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=1)\n",
    "print(train_df.count())\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33632d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c55249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------+\n",
      "|trip_distance|duration|features|\n",
      "+-------------+--------+--------+\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       2|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       3|  [0.01]|\n",
      "|         0.01|       4|  [0.01]|\n",
      "|         0.01|       4|  [0.01]|\n",
      "|         0.01|       4|  [0.01]|\n",
      "|         0.01|       4|  [0.01]|\n",
      "+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vassembler = VectorAssembler(inputCols=['trip_distance'], outputCol='features')\n",
    "vtrain_df = vassembler.transform(train_df)\n",
    "vtrain_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53bbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ec99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=50,\n",
    "                      labelCol=\"duration\",\n",
    "                      featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c4bac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c457bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46aa3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = vassembler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "327e1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "627c4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------+----------------+\n",
      "|trip_distance|duration|features|      prediction|\n",
      "+-------------+--------+--------+----------------+\n",
      "|         0.01|       2|  [0.01]|538.494134101831|\n",
      "|         0.01|       3|  [0.01]|538.494134101831|\n",
      "|         0.01|       3|  [0.01]|538.494134101831|\n",
      "|         0.01|       3|  [0.01]|538.494134101831|\n",
      "|         0.01|       3|  [0.01]|538.494134101831|\n",
      "|         0.01|       4|  [0.01]|538.494134101831|\n",
      "|         0.01|       4|  [0.01]|538.494134101831|\n",
      "|         0.01|       4|  [0.01]|538.494134101831|\n",
      "|         0.01|       4|  [0.01]|538.494134101831|\n",
      "|         0.01|       5|  [0.01]|538.494134101831|\n",
      "|         0.01|       5|  [0.01]|538.494134101831|\n",
      "|         0.01|       5|  [0.01]|538.494134101831|\n",
      "|         0.01|       5|  [0.01]|538.494134101831|\n",
      "|         0.01|       6|  [0.01]|538.494134101831|\n",
      "|         0.01|       6|  [0.01]|538.494134101831|\n",
      "|         0.01|       7|  [0.01]|538.494134101831|\n",
      "|         0.01|       7|  [0.01]|538.494134101831|\n",
      "|         0.01|       7|  [0.01]|538.494134101831|\n",
      "|         0.01|       7|  [0.01]|538.494134101831|\n",
      "|         0.01|       7|  [0.01]|538.494134101831|\n",
      "+-------------+--------+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e55bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "distance_list = [1.1, 5.5, 10.5, 30.0]\n",
    "distances_df = spark.createDataFrame(distance_list, DoubleType()).toDF(\"trip_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cc43781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|          1.1|\n",
      "|          5.5|\n",
      "|         10.5|\n",
      "|         30.0|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fd9f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdistances_df = vassembler.transform(distances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "170e874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|trip_distance|features|\n",
      "+-------------+--------+\n",
      "|          1.1|   [1.1]|\n",
      "|          5.5|   [5.5]|\n",
      "|         10.5|  [10.5]|\n",
      "|         30.0|  [30.0]|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdistances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e1ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------------+\n",
      "|trip_distance|features|        prediction|\n",
      "+-------------+--------+------------------+\n",
      "|          1.1|   [1.1]| 676.9693698522087|\n",
      "|          5.5|   [5.5]| 1235.951972881256|\n",
      "|         10.5|  [10.5]|1871.1594763233556|\n",
      "|         30.0|  [30.0]| 4348.468739747544|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(vdistances_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58f93a",
   "metadata": {},
   "source": [
    "# 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0923cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7fe204c7d250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "652be6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3528.3761929145353\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", model.summary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8182fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.018565176935511962\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", model.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b10fcbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|     trip_distance|         duration|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|          10499761|         10499761|\n",
      "|   mean|2.8817192743725615|903.3216602739815|\n",
      "| stddev|3.8198657789721615|3561.592040114176|\n",
      "|    min|              0.01|                1|\n",
      "|    max|             452.0|          1729062|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b621f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
